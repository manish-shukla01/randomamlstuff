{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore, Experiment\n",
    "ws = Workspace('bd04922c-a444-43dc-892f-74d5090f8a9a','mlplayarearg','testdeployment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydatastrore1 = Datastore.get(ws, 'gen2ds1')\n",
    "mydatastrore2 = Datastore.get(ws, 'gen2ds2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from  azureml.pipeline.core.graph import PipelineParameter\n",
    "data_path1 = DataPath(datastore=mydatastrore1, path_on_datastore='somedata')\n",
    "datapath1_pipeline_param = PipelineParameter(name=\"input_datapath1\", default_value=data_path1)\n",
    "datapath_input1 = (datapath1_pipeline_param, DataPathComputeBinding(mode='mount'))\n",
    "\n",
    "data_path2 = DataPath(datastore=mydatastrore2, path_on_datastore='somedata')\n",
    "datapath2_pipeline_param = PipelineParameter(name=\"input_datapath2\", default_value=data_path2)\n",
    "datapath_input2 = (datapath2_pipeline_param, DataPathComputeBinding(mode='mount'))\n",
    "\n",
    "hour_pipeline_param = PipelineParameter(name=\"input_hour\",default_value='2020112913')\n",
    "Override_pipeline_param = PipelineParameter(name=\"override_hour\",default_value='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting step1N.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile step1N.py\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "parser = argparse.ArgumentParser(\"train\")\n",
    "parser.add_argument(\"--arg1\", type=str, help=\"override argument\")\n",
    "parser.add_argument(\"--arg2\", type=str, help=\"sample hour string argument\")\n",
    "parser.add_argument(\"--arg3\", type=str, help=\"sample datapath argument\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mydf1 = pd.read_csv(os.path.join(args.arg3,'mydata.csv'))\n",
    "\n",
    "mydf2 = pd.read_csv(os.path.join(args.arg3,'testdataatroot.csv'))\n",
    "print(mydf1.shape[0])\n",
    "print(mydf2.shape[0])\n",
    "numberofrows = mydf1.shape[0] + mydf2.shape[0]\n",
    "\n",
    "print (args.arg1)\n",
    "if (args.arg1 == 'False'):\n",
    "    currentDT = datetime.datetime.now()\n",
    "    hourstring = currentDT.strftime(\"%Y%m%d%H\")\n",
    "else:\n",
    "    hourstring = args.arg2\n",
    "\n",
    "test = pd.DataFrame(range(1,numberofrows), columns=[\"testColumn\"])\n",
    "for x in range(6):\n",
    "    if not os.path.exists(os.path.join(args.arg3,hourstring)):\n",
    "        print (os.path.join(args.arg3,hourstring))\n",
    "        os.makedirs(os.path.join(args.arg3,hourstring))\n",
    "    csvfilepath = os.path.join(args.arg3,hourstring ,'file' + str(x) + '.csv')\n",
    "    test.to_csv(csvfilepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting step2N.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile step2N.py\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "parser = argparse.ArgumentParser(\"train\")\n",
    "parser.add_argument(\"--arg1\", type=str, help=\"override argument\")\n",
    "parser.add_argument(\"--arg2\", type=str, help=\"sample hour string argument\")\n",
    "parser.add_argument(\"--arg3\", type=str, help=\"sample datapath argument\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mydf1 = pd.read_csv(os.path.join(args.arg3,'mydata.csv'))\n",
    "\n",
    "mydf2 = pd.read_csv(os.path.join(args.arg3,'testdataatroot.csv'))\n",
    "print(mydf1.shape[0])\n",
    "print(mydf2.shape[0])\n",
    "numberofrows = mydf1.shape[0] + mydf2.shape[0]\n",
    "print(args.arg1)\n",
    "if (args.arg1 == 'False'):\n",
    "    currentDT = datetime.datetime.now()\n",
    "    hourstring = currentDT.strftime(\"%Y%m%d%H\")\n",
    "else:\n",
    "    hourstring = args.arg2\n",
    "\n",
    "test = pd.DataFrame(range(1,numberofrows), columns=[\"testColumn\"])\n",
    "for x in range(6):\n",
    "    if not os.path.exists(os.path.join(args.arg3,hourstring)):\n",
    "        print (os.path.join(args.arg3,hourstring))\n",
    "        os.makedirs(os.path.join(args.arg3,hourstring))\n",
    "    csvfilepath = os.path.join(args.arg3,hourstring ,'file' + str(x) + '.csv')\n",
    "    test.to_csv(csvfilepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment \n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "# `compute_target` as defined in \"Azure Machine Learning compute\" section above\n",
    "aml_run_config.target = \"cpu-cluster\"\n",
    "\n",
    "USE_CURATED_ENV = False\n",
    "if USE_CURATED_ENV :\n",
    "    curated_environment = Environment.get(workspace=ws, name=\"AzureML-Tutorial\")\n",
    "    aml_run_config.environment = curated_environment\n",
    "else:\n",
    "    aml_run_config.environment.python.user_managed_dependencies = False\n",
    "    \n",
    "    # Add some packages relied on by data prep step\n",
    "    aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "        conda_packages=['pandas','scikit-learn'], \n",
    "        pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n",
    "        pin_sdk_version=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step1N created\n",
      "train_step2N created\n",
      "pipeline with the train_steps created\n",
      "Created step train_step1N [5503f9ee][cfd344b0-d218-4369-81df-8847bfd271e6], (This step will run and generate new outputs)\n",
      "Created step train_step2N [8a773556][72e1a55b-0bce-4e61-9a90-5f96cc60e7ae], (This step will run and generate new outputs)\n",
      "Using data reference gen2ds1_803d0536 for StepId [ffa387ad][1380ae12-315c-4cfb-a247-e62c499e2de6], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference gen2ds2_dcb9ad80 for StepId [f41073a3][720c7998-45b2-40f4-ab2a-d41b1b0fd516], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun 5bae1822-0f2c-4e05-9a61-cbe0f308de82\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/showcasing-datapathNew/runs/5bae1822-0f2c-4e05-9a61-cbe0f308de82?wsid=/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourcegroups/mlplayarearg/workspaces/testdeployment\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.core import Pipeline, PipelineRun\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "train_step1N = PythonScriptStep(\n",
    "    name='train_step1N',\n",
    "    script_name=\"step1N.py\",\n",
    "    arguments=[\"--arg1\", Override_pipeline_param,\"--arg2\", hour_pipeline_param, \"--arg3\", datapath_input1],\n",
    "    inputs=[datapath_input1],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step1N created\")\n",
    "\n",
    "train_step2N = PythonScriptStep(\n",
    "    name='train_step2N',\n",
    "    script_name=\"step2N.py\",\n",
    "    arguments=[\"--arg1\", Override_pipeline_param,\"--arg2\", hour_pipeline_param, \"--arg3\", datapath_input2],\n",
    "    inputs=[datapath_input2],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step2N created\")\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_step1N,train_step2N])\n",
    "print(\"pipeline with the train_steps created\")\n",
    "\n",
    "experiment_name = 'showcasing-datapathNew'\n",
    "source_directory  = '.'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "newdatastore = Datastore.get(ws,'gen2ds1')\n",
    "new_data_path1 = DataPath(datastore=newdatastore, path_on_datastore='somedata')\n",
    "newdatastore2 = Datastore.get(ws,'gen2ds2')\n",
    "new_data_path2 = DataPath(datastore=newdatastore2, path_on_datastore='somedata')\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline,pipeline_parameters={\"override_hour\": 'True',\"input_hour\":'XYVVVV',\"input_datapath2\":new_data_path2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<azureml.pipeline.core.graph.PipelineParameter at 0x7ff5fc9d9fd0>,\n",
       " <azureml.data.datapath.DataPathComputeBinding at 0x7ff5fc9d9f28>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step1N created\n",
      "train_step2N created\n",
      "pipeline with the train_steps created\n",
      "Created step train_step1N [4b12412a][110cf156-3bc2-4dd3-b41f-d2a09b1ef78d], (This step will run and generate new outputs)Created step train_step2N [c09c4b36][4e408911-edb7-4926-b20b-db713a990837], (This step will run and generate new outputs)\n",
      "\n",
      "Using data reference gen2ds1_803d0536 for StepId [21bc8ae0][1380ae12-315c-4cfb-a247-e62c499e2de6], (Consumers of this data are eligible to reuse prior runs.)Using data reference gen2ds2_dcb9ad80 for StepId [7b78bcda][720c7998-45b2-40f4-ab2a-d41b1b0fd516], (Consumers of this data are eligible to reuse prior runs.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>PublishedForTriggerlaterWithAMLSchedule</td><td><a href=\"https://ml.azure.com/pipelines/85de3502-a6cc-42a7-a1c5-68f7b166cc2a?wsid=/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourcegroups/mlplayarearg/workspaces/testdeployment\" target=\"_blank\" rel=\"noopener\">85de3502-a6cc-42a7-a1c5-68f7b166cc2a</a></td><td>Active</td><td><a href=\"https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourceGroups/mlplayarearg/providers/Microsoft.MachineLearningServices/workspaces/testdeployment/PipelineRuns/PipelineSubmit/85de3502-a6cc-42a7-a1c5-68f7b166cc2a\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: PublishedForTriggerlaterWithAMLSchedule,\n",
       "Id: 85de3502-a6cc-42a7-a1c5-68f7b166cc2a,\n",
       "Status: Active,\n",
       "Endpoint: https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourceGroups/mlplayarearg/providers/Microsoft.MachineLearningServices/workspaces/testdeployment/PipelineRuns/PipelineSubmit/85de3502-a6cc-42a7-a1c5-68f7b166cc2a)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.core import Pipeline, PipelineRun\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "train_step1N = PythonScriptStep(\n",
    "    name='train_step1N',\n",
    "    script_name=\"step1N.py\",\n",
    "    arguments=[\"--arg1\", Override_pipeline_param,\"--arg2\", hour_pipeline_param, \"--arg3\", datapath_input1],\n",
    "    inputs=[datapath_input1],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step1N created\")\n",
    "\n",
    "train_step2N = PythonScriptStep(\n",
    "    name='train_step2N',\n",
    "    script_name=\"step2N.py\",\n",
    "    arguments=[\"--arg1\", Override_pipeline_param,\"--arg2\", hour_pipeline_param, \"--arg3\", datapath_input2],\n",
    "    inputs=[datapath_input2],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step2N created\")\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_step1N,train_step2N])\n",
    "print(\"pipeline with the train_steps created\")\n",
    "\n",
    "\n",
    "pipeline.publish(name='PublishedForTriggerlaterWithAMLSchedule',description='this is awsesome pipeline',version='3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "recurrence = ScheduleRecurrence(frequency=\"Hour\", interval=1)\n",
    "recurring_schedule = Schedule.create(ws, name=\"MyRecurringSchedule from AML\", \n",
    "                            description=\"Based on time\",\n",
    "                            pipeline_id=\"85de3502-a6cc-42a7-a1c5-68f7b166cc2a\", \n",
    "                            experiment_name=\"scheduledruneveryhour\", \n",
    "                            recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Schedule.list(ws)\n",
    "for s in ss:\n",
    "    s.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline, PublishedPipeline\n",
    "pipeline = PublishedPipeline.get(ws, id=\"5a82eb85-05d2-4c0e-be5c-28586b29bb9e\")\n",
    "pipeline.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
