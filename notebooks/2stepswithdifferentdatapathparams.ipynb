{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore, Experiment\n",
    "ws = Workspace('bd04922c-a444-43dc-892f-74d5090f8a9a','mlplayarearg','testdeployment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydatastrore1 = Datastore.get(ws, 'gen2datastoreasblob')\n",
    "mydatastrore2 = Datastore.get(ws, 'gen2datastoreasblob2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from  azureml.pipeline.core.graph import PipelineParameter\n",
    "data_path1 = DataPath(datastore=mydatastrore1, path_on_datastore='somedata')\n",
    "datapath1_pipeline_param = PipelineParameter(name=\"input_datapath1\", default_value=data_path1)\n",
    "datapath_input1 = (datapath1_pipeline_param, DataPathComputeBinding(mode='mount'))\n",
    "\n",
    "data_path2 = DataPath(datastore=mydatastrore2, path_on_datastore='somedata')\n",
    "datapath2_pipeline_param = PipelineParameter(name=\"input_datapath2\", default_value=data_path2)\n",
    "datapath_input2 = (datapath2_pipeline_param, DataPathComputeBinding(mode='mount'))\n",
    "\n",
    "string_pipeline_param = PipelineParameter(name=\"input_string\", default_value='sample_string1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting step1.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile step1.py\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "parser = argparse.ArgumentParser(\"train\")\n",
    "parser.add_argument(\"--arg1\", type=str, help=\"sample string argument\")\n",
    "parser.add_argument(\"--arg2\", type=str, help=\"sample datapath argument\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mydf1 = pd.read_csv(os.path.join(args.arg2,'mydata.csv'))\n",
    "\n",
    "mydf2 = pd.read_csv(os.path.join(args.arg2,'testdataatroot.csv'))\n",
    "print(mydf1.shape[0])\n",
    "print(mydf2.shape[0])\n",
    "numberofrows = mydf1.shape[0] + mydf2.shape[0]\n",
    "\n",
    "test = pd.DataFrame(range(1,numberofrows), columns=[\"testColumn\"])\n",
    "for x in range(6):\n",
    "    if not os.path.exists(os.path.join(args.arg2,args.arg1)):\n",
    "        print (os.path.join(args.arg2,args.arg1))\n",
    "        os.makedirs(os.path.join(args.arg2,args.arg1))\n",
    "    csvfilepath = os.path.join(args.arg2,args.arg1 ,'file' + str(x) + '.csv')\n",
    "    test.to_csv(csvfilepath)\n",
    "\n",
    "print(\"Sample string argument  : %s\" % args.arg1)\n",
    "print(\"Sample datapath argument: %s\" % args.arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting step2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile step2.py\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "parser = argparse.ArgumentParser(\"train\")\n",
    "parser.add_argument(\"--arg1\", type=str, help=\"sample string argument\")\n",
    "parser.add_argument(\"--arg2\", type=str, help=\"sample datapath argument\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mydf1 = pd.read_csv(os.path.join(args.arg2,'mydata.csv'))\n",
    "\n",
    "mydf2 = pd.read_csv(os.path.join(args.arg2,'testdataatroot.csv'))\n",
    "print(mydf1.shape[0])\n",
    "print(mydf2.shape[0])\n",
    "numberofrows = mydf1.shape[0] + mydf2.shape[0]\n",
    "\n",
    "test = pd.DataFrame(range(1,numberofrows), columns=[\"testColumn\"])\n",
    "for x in range(6):\n",
    "    if not os.path.exists(os.path.join(args.arg2,args.arg1)):\n",
    "        print (os.path.join(args.arg2,args.arg1))\n",
    "        os.makedirs(os.path.join(args.arg2,args.arg1), exist_ok = True)\n",
    "    csvfilepath = os.path.join(args.arg2,args.arg1 ,'file' + str(x) + '.csv')\n",
    "    test.to_csv(csvfilepath)\n",
    "\n",
    "print(\"Sample string argument  : %s\" % args.arg1)\n",
    "print(\"Sample datapath argument: %s\" % args.arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment \n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "# `compute_target` as defined in \"Azure Machine Learning compute\" section above\n",
    "aml_run_config.target = \"cpu-cluster\"\n",
    "\n",
    "USE_CURATED_ENV = False\n",
    "if USE_CURATED_ENV :\n",
    "    curated_environment = Environment.get(workspace=ws, name=\"AzureML-Tutorial\")\n",
    "    aml_run_config.environment = curated_environment\n",
    "else:\n",
    "    aml_run_config.environment.python.user_managed_dependencies = False\n",
    "    \n",
    "    # Add some packages relied on by data prep step\n",
    "    aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "        conda_packages=['pandas','scikit-learn'], \n",
    "        pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n",
    "        pin_sdk_version=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step1 created\n",
      "train_step2 created\n",
      "pipeline with the train_steps created\n",
      "Created step train_step1 [53101c75][1bab8338-4062-4a09-b70c-49e887fc0060], (This step will run and generate new outputs)\n",
      "Created step train_step2 [f54932d5][a9834ae1-f324-4ce4-8373-6d1df9aeb50d], (This step will run and generate new outputs)\n",
      "Using data reference newdatastoremanish_19178a81 for StepId [7a970874][22522887-bdc7-4255-9de9-91ff73f6dfcb], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference newdatastoremanish_19178a81 for StepId [b4247355][22522887-bdc7-4255-9de9-91ff73f6dfcb], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun a9bc1662-9705-4a23-a3ae-8d4e9486ee8e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/showcasing-datapath/runs/a9bc1662-9705-4a23-a3ae-8d4e9486ee8e?wsid=/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourcegroups/mlplayarearg/workspaces/testdeployment\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.core import Pipeline, PipelineRun\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "train_step1 = PythonScriptStep(\n",
    "    name='train_step1',\n",
    "    script_name=\"step1.py\",\n",
    "    arguments=[\"--arg1\", string_pipeline_param, \"--arg2\", datapath_input1],\n",
    "    inputs=[datapath_input1],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step1 created\")\n",
    "\n",
    "train_step2 = PythonScriptStep(\n",
    "    name='train_step2',\n",
    "    script_name=\"step2.py\",\n",
    "    arguments=[\"--arg1\", string_pipeline_param, \"--arg2\", datapath_input2],\n",
    "    inputs=[datapath_input2],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step2 created\")\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_step1,train_step2])\n",
    "print(\"pipeline with the train_steps created\")\n",
    "\n",
    "experiment_name = 'showcasing-datapath'\n",
    "source_directory  = '.'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "newdatastore = Datastore.get(ws,'gen2datastoreasblob')\n",
    "new_data_path1 = DataPath(datastore=newdatastore, path_on_datastore='somedata')\n",
    "newdatastore2 = Datastore.get(ws,'gen2datastoreasblob2')\n",
    "new_data_path2 = DataPath(datastore=newdatastore2, path_on_datastore='somedata')\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline,pipeline_parameters={\"input_string\": \"20201127110800\",\"input_datapath1\":new_data_path1,\"input_datapath2\":new_data_path2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<azureml.pipeline.core.graph.PipelineParameter at 0x7ff5fc9d9fd0>,\n",
       " <azureml.data.datapath.DataPathComputeBinding at 0x7ff5fc9d9f28>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step1 created\n",
      "train_step2 created\n",
      "pipeline with the train_steps created\n",
      "Created step train_step1 [3ff0c312][8fa93624-848e-45de-a15d-c1137cdc2842], (This step will run and generate new outputs)\n",
      "Created step train_step2 [92c03f92][27687da4-2d7c-4682-91a2-aa8e89bfb405], (This step will run and generate new outputs)\n",
      "Created data reference gen2datastoreasblob_751c8811 for StepId [01dbc3d8][61593f49-1560-4dbb-a321-c0e18c582bc1], (Consumers of this data will generate new runs.)\n",
      "Created data reference gen2datastoreasblob2_981d8e0d for StepId [a138a5f0][4a762f56-980e-445f-8e53-90e49c3d7334], (Consumers of this data will generate new runs.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>PublishedForTriggerlater</td><td><a href=\"https://ml.azure.com/pipelines/9f116f0d-2d43-4f1e-bfab-33400de1b1f2?wsid=/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourcegroups/mlplayarearg/workspaces/testdeployment\" target=\"_blank\" rel=\"noopener\">9f116f0d-2d43-4f1e-bfab-33400de1b1f2</a></td><td>Active</td><td><a href=\"https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourceGroups/mlplayarearg/providers/Microsoft.MachineLearningServices/workspaces/testdeployment/PipelineRuns/PipelineSubmit/9f116f0d-2d43-4f1e-bfab-33400de1b1f2\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: PublishedForTriggerlater,\n",
       "Id: 9f116f0d-2d43-4f1e-bfab-33400de1b1f2,\n",
       "Status: Active,\n",
       "Endpoint: https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/bd04922c-a444-43dc-892f-74d5090f8a9a/resourceGroups/mlplayarearg/providers/Microsoft.MachineLearningServices/workspaces/testdeployment/PipelineRuns/PipelineSubmit/9f116f0d-2d43-4f1e-bfab-33400de1b1f2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.core import Pipeline, PipelineRun\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "train_step1 = PythonScriptStep(\n",
    "    name='train_step1',\n",
    "    script_name=\"step1.py\",\n",
    "    arguments=[\"--arg1\", string_pipeline_param, \"--arg2\", datapath_input1],\n",
    "    inputs=[datapath_input1],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step1 created\")\n",
    "\n",
    "train_step2 = PythonScriptStep(\n",
    "    name='train_step2',\n",
    "    script_name=\"step2.py\",\n",
    "    arguments=[\"--arg1\", string_pipeline_param, \"--arg2\", datapath_input2],\n",
    "    inputs=[datapath_input2],\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory='.')\n",
    "print(\"train_step2 created\")\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_step1,train_step2])\n",
    "print(\"pipeline with the train_steps created\")\n",
    "\n",
    "\n",
    "pipeline.publish(name='PublishedForTriggerlater',description='this is awsesome pipeline',version='3.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
